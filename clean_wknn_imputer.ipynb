{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import dcor\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scale(x, min, max):\n",
    "    ''' \n",
    "    Min/Max Scaler [0,1] that also handles when the max=min.\n",
    "    Inputs:\n",
    "    x (int) - Value to be normalized\n",
    "    min (int) - minmum value\n",
    "    max (int) - maximum value\n",
    "\n",
    "    Outputs:\n",
    "    norm (int) - normalized value [0,1]\n",
    "    '''\n",
    "    if min != max:\n",
    "        scaled = max - min\n",
    "    else:\n",
    "        scaled = 1\n",
    "    norm = (x - min) / scaled\n",
    "    return norm\n",
    "\n",
    "\n",
    "def get_mean_val_dict(df, lab_value_names):\n",
    "    ''' \n",
    "    Creates a dictionary with the mean lab values. \n",
    "\n",
    "    Inputs:\n",
    "    df (DataFrame): Contains lab values as columns.\n",
    "    lab_value_names (list): list of strings that correspond to \n",
    "    column headers of each lab value in the DataFrame\n",
    "\n",
    "    Outputs:\n",
    "    means_dict (Dict): Dictionary with keys as column headers (str)\n",
    "    and values as mean lab values (int) \n",
    "    '''\n",
    "    mean_norm_values = []\n",
    "    for lab in lab_value_names:\n",
    "        values = df[lab].dropna()\n",
    "        min_lab = min(values)\n",
    "        max_lab = max(values)\n",
    "        mean_value = values.mean()\n",
    "        norm_lab_val = minmax_scale(mean_value, min_lab, max_lab)\n",
    "        mean_norm_values.append(norm_lab_val)\n",
    "    means_dict = dict(map(lambda i,j : (i,j) , lab_value_names, mean_norm_values))\n",
    "    return means_dict\n",
    "\n",
    "\n",
    "def whole_population_normalize_and_split(df, folder_path, lab_value_names):\n",
    "    '''  \n",
    "    Min-max normalize values column wise in a given DataFrame and \n",
    "    separates rows into individual DataFrames grouped by a\n",
    "    given patient ID. The individual DataFrame contains all rows \n",
    "    from the original DataFrame for a given patient ID.\n",
    "\n",
    "    Inputs:\n",
    "    df (DataFrame): Contains the values to be normalized. Must\n",
    "    also include an identifier linking any rows to the same individual.\n",
    "    file_path\n",
    "    folder_path (str): Path to a folder to save individual DataFrames\n",
    "    saved as .csv files\n",
    "    lab_value_names (list): list of strings that correspond to \n",
    "    column headers of each lab value in the DataFrame\n",
    "\n",
    "    Outputs:\n",
    "    Returns nothing, but saves individual DataFrames as .csv\n",
    "    files in the specified folder given by the folder_path\n",
    "    parameter.\n",
    "    '''\n",
    "    mean_norm_values = get_mean_val_dict(df, lab_value_names)\n",
    "    na_reference = df.copy().isnull()\n",
    "    for i, lab in enumerate(lab_value_names):\n",
    "        values = df[lab].dropna()\n",
    "        min_lab = min(values)\n",
    "        max_lab = max(values)\n",
    "        for row in range(len(df)):\n",
    "            check_missing = na_reference.loc[row, lab]\n",
    "            if check_missing == False:\n",
    "                value = df.loc[row, lab]\n",
    "                norm_val = minmax_scale(value, min_lab, max_lab)\n",
    "                df.loc[row, lab] = norm_val\n",
    "    patient_id_lst = list(df.patient_id.unique())\n",
    "    for patient in patient_id_lst:\n",
    "        patient_df = df[df['patient_id'] == patient].reset_index(drop=True)\n",
    "        path = folder_path + str(patient) + '.csv'\n",
    "        patient_df.to_csv(path, index=False)\n",
    "    return print(\"Individual DataFrames saved to: \", folder_path)\n",
    "\n",
    "\n",
    "def indivdual_normalize_and_split(df, folder_path, lab_value_names):\n",
    "    '''  \n",
    "    Min-max normalize values column wise in a given DataFrame and \n",
    "    separates rows into individual DataFrames grouped by a\n",
    "    given patient ID. The individual DataFrame contains all rows \n",
    "    from the original DataFrame for a given patient ID.\n",
    "\n",
    "    Inputs:\n",
    "    df (DataFrame): Contains the values to be normalized. Must\n",
    "    also include an identifier linking any rows to the same individual.\n",
    "    file_path\n",
    "    folder_path (str): Path to a folder to save individual DataFrames\n",
    "    saved as .csv files\n",
    "    lab_value_names (list): list of strings that correspond to \n",
    "    column headers of each lab value in the DataFrame\n",
    "\n",
    "    Outputs:\n",
    "    Returns nothing, but saves individual DataFrames as .csv\n",
    "    files in the specified folder given by the folder_path\n",
    "    parameter.\n",
    "    '''\n",
    "    mean_norm_values = get_mean_val_dict(df, lab_value_names)\n",
    "    patient_id_lst = list(df.patient_id.unique())\n",
    "    for patient in patient_id_lst:\n",
    "        patient_df = df[df['patient_id'] == patient].reset_index(drop=True)\n",
    "        na_reference_df = patient_df.copy()\n",
    "        na_reference_df = na_reference_df.isnull()\n",
    "        for i, lab in enumerate(lab_value_names):\n",
    "            total_missing = patient_df[lab].isnull().sum()\n",
    "            if total_missing == 5: \n",
    "                continue\n",
    "            else:\n",
    "                values = patient_df[lab].dropna()\n",
    "                min_lab = min(values)\n",
    "                max_lab = max(values)\n",
    "                for v in range(0, patient_df.shape[0]):\n",
    "                    is_missing = na_reference_df.loc[v, lab]\n",
    "                    if is_missing == False:\n",
    "                        value = patient_df.loc[v, lab]\n",
    "                        norm_val = minmax_scale(value, min_lab, max_lab)\n",
    "                        patient_df.loc[v, lab] = norm_val\n",
    "        path = folder_path + str(patient) + '.csv'\n",
    "        patient_df.to_csv(path, index=False)\n",
    "    return print(\"Individual DataFrames saved to: \", folder_path)\n",
    "\n",
    "\n",
    "def get_correlation_dict(df, lab_value_names):\n",
    "    '''  \n",
    "    Create a dictionary of dictionaries, where the first key is a lab name,\n",
    "    with the value of a second dictionary. The second dictionary key is the\n",
    "    name of the lab value between which the correlation distance is calculated\n",
    "    between the lab named as the key to the first dictionary. The value of the \n",
    "    second dictionary is the correlation distance between the two labs.\n",
    "    Example: {'crp': {'wbc':0.64}}\n",
    "\n",
    "    Inputs:\n",
    "    df (DataFrame): Contains lab values in the columns and patients in the rows\n",
    "    lab_value_names (list): List of strings that represent the column headers\n",
    "    for each lab value that should be used to calculate a correlation distance.\n",
    "\n",
    "    Outputs:\n",
    "    correlation_dict (Dict): Contains distance correlation in the format described\n",
    "    above. \n",
    "    '''\n",
    "    individual_labs = []\n",
    "    for lab in lab_value_names: \n",
    "        lab_data = df[lab].dropna()\n",
    "        lab_data = lab_data.to_numpy()\n",
    "        individual_labs.append(lab_data)\n",
    "    whole_correlation_dict = dict()\n",
    "    for i, lab_1 in enumerate(individual_labs):\n",
    "        all_cors = []\n",
    "        len_l1 = len(lab_1)\n",
    "        sub_correlation_dict = dict()\n",
    "        for j, lab_2 in enumerate(individual_labs):\n",
    "            len_l2 = len(lab_2)\n",
    "            min_len = min(len_l1, len_l2)\n",
    "            red_1 = lab_1[:min_len]\n",
    "            red_2 = lab_2[:min_len]\n",
    "            correlation = dcor.distance_correlation(red_1, red_2)\n",
    "            sub_correlation_dict[lab_value_names[j]] = correlation\n",
    "        whole_correlation_dict[lab_value_names[i]] = sub_correlation_dict\n",
    "    return whole_correlation_dict\n",
    "\n",
    "\n",
    "def get_correlation_matrix(df, lab_value_names):\n",
    "    '''  \n",
    "    Create a correlation matrix as a DataFrame describing the distance\n",
    "    correlation between lab values.\n",
    "\n",
    "    Inputs:\n",
    "    df (DataFrame): Contains lab values in the columns and patients in the rows\n",
    "    lab_value_names (list): List of strings that represent the column headers\n",
    "    for each lab value that should be used to calculate a correlation distance.\n",
    "\n",
    "    Outputs:\n",
    "    correlation_matrix (DataFrame): column headers are the same as index \n",
    "    values, thereby making a confusion matrix of distance correlations\n",
    "    among the lab values. \n",
    "    '''\n",
    "    individual_labs = []\n",
    "    for lab in lab_value_names: \n",
    "        lab_data = df[lab].dropna()\n",
    "        lab_data = lab_data.to_numpy()\n",
    "        individual_labs.append(lab_data)\n",
    "    l_whole_correlation_dict = dict()\n",
    "    for i, lab_1 in enumerate(individual_labs):\n",
    "        all_cors = []\n",
    "        len_l1 = len(lab_1)\n",
    "        cor_lst = []\n",
    "        for j, lab_2 in enumerate(individual_labs):\n",
    "            len_l2 = len(lab_2)\n",
    "            min_len = min(len_l1, len_l2)\n",
    "            red_1 = lab_1[:min_len]\n",
    "            red_2 = lab_2[:min_len]\n",
    "            correlation = dcor.distance_correlation(red_1, red_2)\n",
    "            cor_lst.append(correlation)\n",
    "        l_whole_correlation_dict[lab_value_names[i]] = cor_lst\n",
    "    correlation_matrix = pd.DataFrame()\n",
    "    correlation_matrix['lab_name'] = lab_value_names\n",
    "    correlation_matrix = correlation_matrix.set_index('lab_name')\n",
    "\n",
    "    for labs, cor_vals in l_whole_correlation_dict.items():\n",
    "        correlation_matrix[labs] = cor_vals\n",
    "    return correlation_matrix\n",
    "\n",
    "\n",
    "def find_neighbors(patient_matrix, visit_v_idx, visit_u_idx, lab_to_impute, correlation_dict):\n",
    "    ''' \n",
    "    Find the distance correlation sum between two given visits. This function\n",
    "    compares the lab values that are mutually present between two visits, accesses\n",
    "    the distance correlation between those labs, and sums the distance correlation\n",
    "    between the lab value that is missing and the lab values that contain measurments\n",
    "    in both visits. \n",
    "\n",
    "    Example: Visit 1 has lab values for cal, pro, fol, fer, hgb, hct, and wbc. Visit 2 has\n",
    "    values for alt, pro, alb, hgb, pmn, wbc, fer, btwelve, and hct. The value being imputed is \n",
    "    plt. This function identifies that both visits have lab values for pro, wbc, fer, hct, and\n",
    "    hgb. Then, it identifies the distance correlation between pro-plt, wbc-plt, fer-plt, hct-plt,\n",
    "    and hgb-plt. Finally, the identified distance correlations are summed together, which is then\n",
    "    used to calculate the distance metric. The inverse distance metric and the \n",
    "    value of the comparator visit (visit_u) are saved and used for the output.\n",
    "\n",
    "    Inputs:\n",
    "    patient_matrix (DataFrame): contains labs as columns and visits as rows\n",
    "    visit_d_idx (int): index for the visit that contains the value to be imputed.\n",
    "    visit_u_idx (int): index for the visit being compared to the visit with the value\n",
    "    that is to be imputed. \n",
    "    lab_to_impute (str): represents the lab type (column header) of the value being imputed\n",
    "\n",
    "    Outputs:\n",
    "    weights, values (tuple [list, list]): Weights of each neighbor and the value\n",
    "    of the neighbor, each stored in a list where the index of the list \n",
    "    corresponds to matching weights and values. \n",
    "    '''\n",
    "    visit_v = patient_matrix.loc[visit_v_idx,:].dropna()\n",
    "    visit_u = patient_matrix.loc[visit_u_idx, :].dropna()\n",
    "    v_labs = list(visit_v.index)\n",
    "    u_labs = list(visit_u.index)\n",
    "    shared_labs = [l for l in v_labs and u_labs if l in v_labs and l in u_labs]\n",
    "    if len(shared_labs) == 0:\n",
    "        return []\n",
    "    correlation_vals = []\n",
    "    for l in shared_labs:\n",
    "        val = correlation_dict[lab_to_impute][l]\n",
    "        correlation_vals.append(val)\n",
    "    sum_dis_cors = sum(correlation_vals)\n",
    "    weights_values = []\n",
    "    for l in shared_labs:\n",
    "        v_j = visit_v.loc[l]\n",
    "        u_j = visit_u.loc[l]\n",
    "        distance_metric = math.sqrt(sum_dis_cors * (v_j - u_j)**2) / sum_dis_cors\n",
    "        # Calculate the inverse of the distance metric because the smaller the distance\n",
    "        # the larger the weight (i.e. closer neighbor), we can then say that larger \n",
    "        # weights are closer, instead of working with smaller distances.\n",
    "        weight = 1 / (distance_metric + 1e-6) # add epsilon to avoid division by 0\n",
    "        weights_values.append((weight, u_j))\n",
    "    return weights_values\n",
    "\n",
    "\n",
    "def impute_wknn(k, patient_matrix, mask_matrix, lab, visit_idx, correlation_matrix, correlation_dict, means_dict):\n",
    "    ''' \n",
    "    Impute missing lab values given a patient matrix.\n",
    "\n",
    "    Inputs:\n",
    "    k (integer): k-number of neighbors to use when imputing\n",
    "    patient_matrix (DataFrame): contains labs as columns and visits as rows\n",
    "    mask_matrix (DataFrame): Boolean mask of the patient matrix where True = null\n",
    "    and False = int. \n",
    "    lab (str): lab type (column header) of the missing value\n",
    "    visit_idx (int): index in the patient matrix of the visit from which the missing value arises\n",
    "\n",
    "    Output:\n",
    "    imputed_value (int): Imputed value for the missing values of a given lab\n",
    "    for a given patient.\n",
    "    '''\n",
    "    # Loop and get data pairs to calculate d(u,v)\n",
    "    all_weights_values = []\n",
    "    value = mask_matrix.loc[visit_idx, lab]\n",
    "    # impute missing value\n",
    "    for i in range(0, patient_matrix.shape[0]):\n",
    "        if visit_idx == i: # Do not want to compare a visit to itself\n",
    "            continue\n",
    "        if mask_matrix.loc[i, lab] == True: # Make sure the comparing visit has a value\n",
    "            continue\n",
    "        else:\n",
    "            weights_values = find_neighbors(patient_matrix, visit_idx, i, lab, correlation_matrix)\n",
    "        all_weights_values = all_weights_values + weights_values\n",
    "    if len(all_weights_values) == 0: \n",
    "        # Set imputed value to mean if there are no neighbors\n",
    "        imputed_value = means_dict[lab]\n",
    "    else:     \n",
    "        sorted_weights_vals = sorted(all_weights_values)\n",
    "        neighbors = sorted_weights_vals[:k]  \n",
    "        w_knn, v_knn = map(list,zip(*sorted_weights_vals))\n",
    "        v_knn = np.asarray(v_knn)\n",
    "        w_knn = np.asarray(w_knn)\n",
    "        norm_weights = w_knn / sum(w_knn)\n",
    "        imputed_value = sum(v_knn * norm_weights)\n",
    "    return imputed_value\n",
    "\n",
    "def combine_dataframes(imputed_folder_path, imputed_file_path):\n",
    "    ''' \n",
    "    Combines individual DataFrames into one DataFrame. Note: this\n",
    "    function assumes that the DataFrame contains specific column\n",
    "    headers. Please see README for more details.\n",
    "\n",
    "    Inputs:\n",
    "    imputed_folder_path (str): Folder path to where imputed individual\n",
    "    files are saved.\n",
    "    imputed_file_path (str): Path to save single .csv file of combined DataFrames\n",
    "\n",
    "    Outputs:\n",
    "    Returns nothing. Saves combined DataFrame at the location specified by\n",
    "    the imputed_file_path parameter.\n",
    "    '''\n",
    "    impute_file_lst = os.listdir(imputed_folder_path) \n",
    "    column_labels = []\n",
    "    visit_lst = []\n",
    "    all_patients_df = pd.DataFrame()\n",
    "    for pt in impute_file_lst:\n",
    "        if '.D' in pt:\n",
    "            continue\n",
    "        path = imputed_folder_path + '/' + pt \n",
    "        imputed_pt = pd.read_csv(path)\n",
    "        imputed_pt = imputed_pt.drop('year', axis=1)\n",
    "        for i in range(0,imputed_pt.shape[0]):\n",
    "            label = str(i + 1)\n",
    "            visit = imputed_pt.iloc[i, 1:]\n",
    "            patient_id = imputed_pt.loc[0, 'patient_id']\n",
    "            column_labels = column_labels + [x + label for x in list(visit.index)]\n",
    "            visit_lst = visit_lst + visit.to_list() \n",
    "        full_dict = dict(zip(column_labels, visit_lst))\n",
    "        df = pd.DataFrame(full_dict, index=[0])\n",
    "        df['patient_id'] = patient_id\n",
    "        all_patients_df = pd.concat([all_patients_df, df], axis=0 )\n",
    "    all_patients_df.to_csv(imputed_file_path, index=False)\n",
    "    return print(\"Imputed DataFrames have been combined and saved as: \", imputed_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_wknn_imputer(df, folder_path, imputed_folder_path, imputed_file_path, level='individual'):\n",
    "    ''' \n",
    "    Performs distance correlation weighted KNN imputation\n",
    "    on a given dataset. Note: the dataset must contain \n",
    "    specific column headers. See README for exact DataFrame format\n",
    "    specifications for compatability with this function.\n",
    "\n",
    "    Inputs:\n",
    "    df (DataFrame): DataFrame to perform imputation on. \n",
    "    folder_path (str): Folder path where NON-IMPUTED individual \n",
    "    files can be saved after splitting the larger dataframe into\n",
    "    patient-level dataframes.\n",
    "    imputed_file_path (str): Path to save single .csv file of combined DataFrames\n",
    "    level (str): Denotes which normalize and split method to use. 'individual' \n",
    "    will split the dataframe and normalize patients at the patient level.\n",
    "    'whole_pop' will normalize values across the whole dataframe before splitting at the patient level.\n",
    "\n",
    "    Outputs: \n",
    "    Returns nothing. Imputed individual DataFrames are saved in the \n",
    "    folder specified by impute_folder_path.\n",
    "    '''\n",
    "    lab_value_names = list(df.columns.values)\n",
    "    lab_value_names = lab_value_names[1:-1]\n",
    "    if level == 'individual':\n",
    "        indivdual_normalize_and_split(df, folder_path, lab_value_names)\n",
    "    if level == 'whole_pop':\n",
    "        whole_population_normalize_and_split(df, folder_path, lab_value_names)\n",
    "    correlation_dict = get_correlation_dict(df, lab_value_names)\n",
    "    correlation_matrix = get_correlation_matrix(df, lab_value_names)\n",
    "    means_dict = get_mean_val_dict(df, lab_value_names)\n",
    "    split_file_lst = os.listdir(folder_path)\n",
    "    for pt in split_file_lst: \n",
    "        if '.D' in pt:\n",
    "            continue\n",
    "        path = folder_path + '/' + pt \n",
    "        patient_matrix = pd.read_csv(path)\n",
    "        patient_id = patient_matrix.loc[0, 'patient_id']\n",
    "        patient_matrix = patient_matrix.reset_index(drop=True)\n",
    "        # Create a dataframe containing only the lab values:\n",
    "        labs_only_patient_matrix = patient_matrix.drop(['patient_id', 'year'], axis=1)\n",
    "        mask_visits = labs_only_patient_matrix.isnull()\n",
    "        for lab in lab_value_names: # look through each lab in a given visit\n",
    "            for n in range(0, labs_only_patient_matrix.shape[0]): \n",
    "                value = mask_visits.loc[n, lab] # check the value of the lab\n",
    "                if value == True: # value is missing â€” impute\n",
    "                    imputed_value = impute_wknn(3, \n",
    "                                                labs_only_patient_matrix, \n",
    "                                                mask_visits, \n",
    "                                                lab, \n",
    "                                                n, \n",
    "                                                correlation_matrix,\n",
    "                                                correlation_dict,\n",
    "                                                means_dict)\n",
    "                    patient_matrix.loc[n, lab] = imputed_value\n",
    "        patient_path = imputed_folder_path + '/'+ str(patient_id) + '_imputed.csv'\n",
    "        patient_matrix.to_csv(patient_path, index=False)\n",
    "    combine_dataframes(imputed_folder_path, imputed_file_path)\n",
    "    return (\"Imputation Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Function on Patient Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets (MacBook Pro)\n",
    "uc = pd.read_csv('/Users/emmadyer/Desktop/long_ibd_data/data/expanded_raw/uc_expanded.csv')\n",
    "cd = pd.read_csv('/Users/emmadyer/Desktop/long_ibd_data/data/expanded_raw/cd_expanded.csv')\n",
    "healthy = pd.read_csv('/Users/emmadyer/Desktop/long_ibd_data/data/expanded_raw/healthy_expanded.csv')\n",
    "\n",
    "dfs = [uc, cd, healthy]\n",
    "\n",
    "split_folders = [ '/Users/emmadyer/Desktop/long_ibd_data/data/uc_pts/',\n",
    "                '/Users/emmadyer/Desktop/long_ibd_data/data/cd_pts/',\n",
    "                '/Users/emmadyer/Desktop/long_ibd_data/data/healthy_pts/']\n",
    "\n",
    "imp_file_paths = ['/Users/emmadyer/Desktop/long_ibd_data/data/ind_uc_imputed.csv',\n",
    "                    '/Users/emmadyer/Desktop/long_ibd_data/data/ind_cd_imputed.csv',\n",
    "                    '/Users/emmadyer/Desktop/long_ibd_data/data/ind_healthy_imputed.csv']\n",
    "\n",
    "imp_folder_paths = [ '/Users/emmadyer/Desktop/long_ibd_data/data/uc_imputed',\n",
    "                    '/Users/emmadyer/Desktop/long_ibd_data/data/cd_imputed',\n",
    "                    '/Users/emmadyer/Desktop/long_ibd_data/data/healthy_imputed']\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    dc_wknn_imputer(df, split_folders[i], imp_folder_paths[i], imp_file_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_wknn_imputer(healthy, '/Users/emmadyer/Desktop/long_ibd_data/data/healthy_pts/', \n",
    "                    '/Users/emmadyer/Desktop/long_ibd_data/data/healthy_imputed',\n",
    "                    '/Users/emmadyer/Desktop/long_ibd_data/data/ind_healthy_imputed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a Master File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_codes = [2,1,0]\n",
    "all_imp = []\n",
    "\n",
    "for i, f in enumerate(imp_file_paths):\n",
    "    df = pd.read_csv(f)\n",
    "    df['ibd_disease_code'] = disease_codes[i]\n",
    "    all_imp.append(df)\n",
    "\n",
    "all_imputed = pd.concat(all_imp, axis=0)\n",
    "all_imputed.to_csv('/Users/emmadyer/Desktop/long_ibd_data/data/ind_all_labs_imputed.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "819f5faae82d2b37d0a346b6fdcf3a45ded9957c5c76ee733e99f4e9e472ef0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
