{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the Data and Separate Patients into Individual Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets (Desktop)\n",
    "uc = pd.read_csv('/Users/emmadyer/Desktop/ibd_long_project/data/uc_expanded.csv')\n",
    "cd = pd.read_csv('/Users/emmadyer/Desktop/ibd_long_project/data/cd_expanded.csv')\n",
    "healthy = pd.read_csv('/Users/emmadyer/Desktop/ibd_long_project/data/healthy_expanded.csv')\n",
    "test_ibd = pd.read_csv('/Users/emmadyer/Desktop/ibd_long_project/data/test_ibd_expanded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for Emma's Macbook \n",
    "\n",
    "# Load Datasets\n",
    "uc = pd.read_csv('/Users/emmadyer/Desktop/data/uc_expanded.csv')\n",
    "cd = pd.read_csv('/Users/emmadyer/Desktop/data/cd_expanded.csv')\n",
    "healthy = pd.read_csv('/Users/emmadyer/Desktop/data/healthy_expanded.csv')\n",
    "test_ibd = pd.read_csv('/Users/emmadyer/Desktop/data/test_ibd_expanded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the lab values (column headers)\n",
    "lab_value_names = list(healthy.columns.values)\n",
    "lab_value_names = lab_value_names[1:-1]\n",
    "\n",
    "# Make a list of the DataFrames\n",
    "all_dfs = [uc, cd, healthy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Each Patient's Data\n",
    "# Min/Max scaling [0,1] and account for missing values\n",
    "def minmax_scale(x, min, max):\n",
    "    ''' \n",
    "    Min/Max Scaler [0,1] that also handles when the max=min.\n",
    "    Inputs:\n",
    "    x (int) - Value to be normalized\n",
    "    min (int) - minmum value\n",
    "    max (int) - maximum value\n",
    "\n",
    "    Outputs:\n",
    "    norm (int) - normalized value [0,1]\n",
    "    '''\n",
    "    if min != max:\n",
    "        scaled = max - min\n",
    "    else:\n",
    "        scaled = 1\n",
    "    norm = (x - min) / scaled\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'crp': 0.00932038236897726, 'fer': 0.020717286113845153, 'btwelve': 0.10243503097824741, 'fol': 0.17204105629757652, 'alb': 0.3433627803575186, 'alp': 0.05830167372121762, 'alt': 0.019750794718491914, 'pro': 0.3113995052460133, 'crt': 0.11570198465126676, 'uac': 0.11161569626732529, 'cal': 0.36153871230372253, 'vtd': 0.06176577165226861, 'hgb': 0.5673972428928927, 'mcv': 0.5840737035916654, 'hct': 0.5653954387423691, 'wbc': 0.05864585235919679, 'pmn': 0.06497447424218497, 'plt': 0.24647898089009923}\n"
     ]
    }
   ],
   "source": [
    "dataset_norms = []\n",
    "lst_of_norm_dicts = []\n",
    "for df in all_dfs:\n",
    "    pts_lst = []\n",
    "    mean_norm_values = []\n",
    "    for lab in lab_value_names:\n",
    "        #print(\"Lab Name: \", lab)\n",
    "        values = df[lab].fillna(0)\n",
    "        #values = values.astype(np.float16)\n",
    "        min_lab = min(values)\n",
    "        #print(\"Minimum Value: \", min_lab)\n",
    "        max_lab = max(values)\n",
    "        #print(\"Maximum Value: \", max_lab)\n",
    "        mean_value = values.mean()\n",
    "        norm_lab_val = minmax_scale(mean_value, min_lab, max_lab)\n",
    "        #print('Scaled Value: ', norm_lab_val, '\\n')\n",
    "        mean_norm_values.append(norm_lab_val)\n",
    "    #dataset_norms.append(mean_norm_values)\n",
    "    # Mean norms dictionary\n",
    "    #print(dataset_norms)\n",
    "    means_dict = dict(map(lambda i,j : (i,j) , lab_value_names, mean_norm_values))\n",
    "    print(means_dict)\n",
    "    lst_of_norm_dicts.append(means_dict)\n",
    "\n",
    "#uc_means_dict = lst_of_norm_dicts[0]\n",
    "#cd_means_dict = lst_of_norm_dicts[1]\n",
    "#healthy_means_dict = lst_of_norm_dicts[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688\n",
      "2197\n",
      "5415\n"
     ]
    }
   ],
   "source": [
    "# Need to calculate a mean normalized value in the event that a given patient only has one recorded value or no values.\n",
    "# Mean Noramlized Values\n",
    "\n",
    "# Lists to store patient normalized dataframes\n",
    "all_patients_lsts = []\n",
    "file_names = ['uc', 'cd', 'healthy']\n",
    "for pt_population, df in enumerate(all_dfs):\n",
    "    mean_norm_values = dataset_norms[pt_population]\n",
    "    patient_id_lst = list(df.patient_id.unique())\n",
    "    print(len(patient_id_lst))\n",
    "    for patient in patient_id_lst:\n",
    "        patient_df = df[df['patient_id'] == patient].reset_index(drop=True)\n",
    "        # Patient Normalized Values\n",
    "        visits = list(range(0,5))\n",
    "        na_reference_df = patient_df.copy()\n",
    "        na_reference_df = na_reference_df.isnull()\n",
    "        #norm_df = patient_df.copy().reset_index()\n",
    "        for i, lab in enumerate(lab_value_names):\n",
    "            #print(\"\\n Lab Name: \", lab)\n",
    "            total_missing = patient_df[lab].isnull().sum()\n",
    "            if total_missing == 5: \n",
    "                continue\n",
    "            else:\n",
    "                values = patient_df[lab].fillna(0)\n",
    "                min_lab = min(values)\n",
    "                max_lab = max(values)\n",
    "                #print(\"Minimum Value: \", min_lab)\n",
    "                #print(\"Maximum Value: \", max_lab)\n",
    "                for v in visits:\n",
    "                    is_missing = na_reference_df.loc[v, lab]\n",
    "                    #print(\"Missing???: \", is_missing)\n",
    "                    if is_missing == False:\n",
    "                        value = patient_df.loc[v, lab]\n",
    "                        norm_val = minmax_scale(value, min_lab, max_lab)\n",
    "                        patient_df.loc[v, lab] = norm_val\n",
    "                    #print(\"Lab Value: \", value)\n",
    "                    #print('Scaled Value: ', norm_val)\n",
    "        pts_lst.append(patient_df)\n",
    "        file_path = '/Users/emmadyer/Desktop/ibd_long_project/data/' + file_names[pt_population] + '_pts/' + str(patient) + '.csv'\n",
    "        patient_df.to_csv(file_path, index=False)\n",
    "        #print(norm_df)\n",
    "    all_patients_lsts.append(pts_lst)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Distance Correlation\n",
    "This is calculated on the whole dataset. We are solving for the distance between two vectors. In this case, we are calculating the distance correlation for the pairwise vectors for each analyte. \n",
    "1. Create individual arrays of each analyte with NA values removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "import dcor\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for Emma's Macbook \n",
    "\n",
    "# Load Datasets\n",
    "uc = pd.read_csv('/Users/emmadyer/Desktop/data/uc_expanded.csv')\n",
    "cd = pd.read_csv('/Users/emmadyer/Desktop/data/cd_expanded.csv')\n",
    "healthy = pd.read_csv('/Users/emmadyer/Desktop/data/healthy_expanded.csv')\n",
    "test_ibd = pd.read_csv('/Users/emmadyer/Desktop/data/test_ibd_expanded.csv')\n",
    "\n",
    "# Make a list of the lab values (column headers)\n",
    "lab_value_names = list(healthy.columns.values)\n",
    "lab_value_names = lab_value_names[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_ibd.copy()\n",
    "individual_labs = []\n",
    "for lab in lab_value_names: \n",
    "    lab_data = df[lab].dropna()\n",
    "    lab_data = lab_data.to_numpy()\n",
    "    individual_labs.append(lab_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate the distance between each array. Need to adjust the arrays to be the same size before calculating the distance correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Correlation Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary of dictionaries. Structure is that the outer key is a lab name,\n",
    "# the inner key is a lab name with a value of the distance correlation between the \n",
    "# two labs specified by the keys\n",
    "\n",
    "whole_correlation_dict = dict()\n",
    "for i, lab_1 in enumerate(individual_labs):\n",
    "    all_cors = []\n",
    "    len_l1 = len(lab_1)\n",
    "    sub_correlation_dict = dict()\n",
    "    for j, lab_2 in enumerate(individual_labs):\n",
    "        len_l2 = len(lab_2)\n",
    "        min_len = min(len_l1, len_l2)\n",
    "        red_1 = lab_1[:min_len]\n",
    "        red_2 = lab_2[:min_len]\n",
    "        correlation = dcor.distance_correlation(red_1, red_2)\n",
    "        sub_correlation_dict[lab_value_names[j]] = correlation\n",
    "    whole_correlation_dict[lab_value_names[i]] = sub_correlation_dict\n",
    "\n",
    "# To test that this is working correctly, we can see that, as expected, the correlation \n",
    "# of crp to crp is 1\n",
    "whole_correlation_dict['crp']['crp']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatted with a list of correlation values\n",
    "\n",
    "\n",
    "l_whole_correlation_dict = dict()\n",
    "for i, lab_1 in enumerate(individual_labs):\n",
    "    all_cors = []\n",
    "    len_l1 = len(lab_1)\n",
    "    cor_lst = []\n",
    "    for j, lab_2 in enumerate(individual_labs):\n",
    "        len_l2 = len(lab_2)\n",
    "        min_len = min(len_l1, len_l2)\n",
    "        red_1 = lab_1[:min_len]\n",
    "        red_2 = lab_2[:min_len]\n",
    "        correlation = dcor.distance_correlation(red_1, red_2)\n",
    "        cor_lst.append(correlation)\n",
    "    l_whole_correlation_dict[lab_value_names[i]] = cor_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance from the missing data point (to be imputed) to ALL\n",
    "# available values\n",
    "\n",
    "# Create a DataFrame with the correlation values (correlation matrix in a dataframe format)\n",
    "correlation_matrix = pd.DataFrame()\n",
    "correlation_matrix['lab_name'] = lab_value_names\n",
    "correlation_matrix = correlation_matrix.set_index('lab_name')\n",
    "\n",
    "for labs, cor_vals in l_whole_correlation_dict.items():\n",
    "    correlation_matrix[labs] = cor_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Function Versions of Correlation Dict and Matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_dict(df, lab_value_names):\n",
    "    '''  \n",
    "    Create a dictionary of dictionaries, where the first key is a lab name,\n",
    "    with the value of a second dictionary. The second dictionary key is the\n",
    "    name of the lab value between which the correlation distance is calculated\n",
    "    between the lab named as the key to the first dictionary. The value of the \n",
    "    second dictionary is the correlation distance between the two labs.\n",
    "    Example: {'crp': {'wbc':0.64}}\n",
    "\n",
    "    Inputs:\n",
    "    df (DataFrame): Contains lab values in the columns and patients in the rows\n",
    "    lab_value_names (list): List of strings that represent the column headers\n",
    "    for each lab value that should be used to calculate a correlation distance.\n",
    "\n",
    "    Outputs:\n",
    "    correlation_dict (Dict): Contains distance correlation in the format described\n",
    "    above. \n",
    "    '''\n",
    "    individual_labs = []\n",
    "    for lab in lab_value_names: \n",
    "        lab_data = df[lab].dropna()\n",
    "        lab_data = lab_data.to_numpy()\n",
    "        individual_labs.append(lab_data)\n",
    "    whole_correlation_dict = dict()\n",
    "    for i, lab_1 in enumerate(individual_labs):\n",
    "        all_cors = []\n",
    "        len_l1 = len(lab_1)\n",
    "        sub_correlation_dict = dict()\n",
    "        for j, lab_2 in enumerate(individual_labs):\n",
    "            len_l2 = len(lab_2)\n",
    "            min_len = min(len_l1, len_l2)\n",
    "            red_1 = lab_1[:min_len]\n",
    "            red_2 = lab_2[:min_len]\n",
    "            correlation = dcor.distance_correlation(red_1, red_2)\n",
    "            sub_correlation_dict[lab_value_names[j]] = correlation\n",
    "        whole_correlation_dict[lab_value_names[i]] = sub_correlation_dict\n",
    "    return whole_correlation_dict\n",
    "\n",
    "def get_correlation_matrix(df, lab_value_names):\n",
    "    '''  \n",
    "    Create a correlation matrix as a DataFrame describing the distance\n",
    "    correlation between lab values.\n",
    "\n",
    "    Inputs:\n",
    "    df (DataFrame): Contains lab values in the columns and patients in the rows\n",
    "    lab_value_names (list): List of strings that represent the column headers\n",
    "    for each lab value that should be used to calculate a correlation distance.\n",
    "\n",
    "    Outputs:\n",
    "    correlation_matrix (DataFrame): column headers are the same as index \n",
    "    values, thereby making a confusion matrix of distance correlations\n",
    "    among the lab values. \n",
    "    '''\n",
    "    individual_labs = []\n",
    "    for lab in lab_value_names: \n",
    "        lab_data = df[lab].dropna()\n",
    "        lab_data = lab_data.to_numpy()\n",
    "        individual_labs.append(lab_data)\n",
    "    l_whole_correlation_dict = dict()\n",
    "    for i, lab_1 in enumerate(individual_labs):\n",
    "        all_cors = []\n",
    "        len_l1 = len(lab_1)\n",
    "        cor_lst = []\n",
    "        for j, lab_2 in enumerate(individual_labs):\n",
    "            len_l2 = len(lab_2)\n",
    "            min_len = min(len_l1, len_l2)\n",
    "            red_1 = lab_1[:min_len]\n",
    "            red_2 = lab_2[:min_len]\n",
    "            correlation = dcor.distance_correlation(red_1, red_2)\n",
    "            cor_lst.append(correlation)\n",
    "        l_whole_correlation_dict[lab_value_names[i]] = cor_lst\n",
    "    correlation_matrix = pd.DataFrame()\n",
    "    correlation_matrix['lab_name'] = lab_value_names\n",
    "    correlation_matrix = correlation_matrix.set_index('lab_name')\n",
    "\n",
    "    for labs, cor_vals in l_whole_correlation_dict.items():\n",
    "        correlation_matrix[labs] = cor_vals\n",
    "    return correlation_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation Steps\n",
    "1. Land on a missing value in the patient matrix.\n",
    "2. Identify if the patient has a non-missing value for the given lab at another visit.\n",
    "3. If there are no data for this lab in any visit, impute with the population mean.\n",
    "4. If there is another data point for this lab value at another visit, calculate the weight d(u,v) between all values, including multiple values of the same lab (that have a correlation of 1)\n",
    "   \n",
    "Note: The summed MIC helps account for temporal relationships. The sum constitutes the sum of MIC for non-missing values that exist in the two vists that are being compared when calculating d(v,u). For example if a patient is missing a value for cal, but they have measurements for crp, fol, hgb, and wbc in visits 1 and 2, the the summed MIC would be calculated as the sum of the MIC values for cal|fol, cal|hgb, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(patient_matrix, visit_v_idx, visit_u_idx, lab_to_impute, correlation_dict=correlation_dict):\n",
    "    ''' \n",
    "    Find the distance correlation sum between two given visits. This function\n",
    "    compares the lab values that are mutually present between two visits, accesses\n",
    "    the distance correlation between those labs, and sums the distance correlation\n",
    "    between the lab value that is missing and the lab values that contain measurments\n",
    "    in both visits. \n",
    "\n",
    "    Example: Visit 1 has lab values for cal, pro, fol, fer, hgb, hct, and wbc. Visit 2 has\n",
    "    values for alt, pro, alb, hgb, pmn, wbc, fer, btwelve, and hct. The value being imputed is \n",
    "    plt. This function identifies that both visits have lab values for pro, wbc, fer, hct, and\n",
    "    hgb. Then, it identifies the distance correlation between pro-plt, wbc-plt, fer-plt, hct-plt,\n",
    "    and hgb-plt. Finally, the identified distance correlations are summed together, which is then\n",
    "    used to calculate the distance metric. The inverse distance metric and the \n",
    "    value of the comparator visit (visit_u) are saved and used for the output.\n",
    "\n",
    "    Inputs:\n",
    "    patient_matrix (DataFrame): contains labs as columns and visits as rows\n",
    "    visit_d_idx (int): index for the visit that contains the value to be imputed.\n",
    "    visit_u_idx (int): index for the visit being compared to the visit with the value\n",
    "    that is to be imputed. \n",
    "    lab_to_impute (str): represents the lab type (column header) of the value being imputed\n",
    "\n",
    "    Outputs:\n",
    "    weights, values (tuple [list, list]): Weights of each neighbor and the value\n",
    "    of the neighbor, each stored in a list where the index of the list \n",
    "    corresponds to matching weights and values. \n",
    "    '''\n",
    "    visit_v = patient_matrix.loc[visit_v_idx,:].dropna()\n",
    "    visit_u = patient_matrix.loc[visit_u_idx, :].dropna()\n",
    "    v_labs = list(visit_v.index)\n",
    "    u_labs = list(visit_u.index)\n",
    "    shared_labs = [l for l in v_labs and u_labs if l in v_labs and l in u_labs]\n",
    "    if len(shared_labs) == 0:\n",
    "        return []\n",
    "    #print(\"Shared Labs: \", shared_labs)\n",
    "    correlation_vals = []\n",
    "    for l in shared_labs:\n",
    "        val = whole_correlation_dict[lab_to_impute][l]\n",
    "        correlation_vals.append(val)\n",
    "    sum_dis_cors = sum(correlation_vals)\n",
    "    #print(\"Distance Correlations Sum: \", sum_dis_cors, '\\n')\n",
    "    weights_values = []\n",
    "    for l in shared_labs:\n",
    "        #print('Lab: ', l)\n",
    "        v_j = visit_v.loc[l]\n",
    "        u_j = visit_u.loc[l]\n",
    "        distance_metric = math.sqrt(sum_dis_cors * (v_j - u_j)**2) / sum_dis_cors\n",
    "        #print(\"Distance Metric: \", distance_metric)\n",
    "        # Calculate the inverse of the distance metric because the smaller the distance\n",
    "        # the larger the weight (i.e. closer neighbor), we can then say that larger \n",
    "        # weights are closer, instead of working with smaller distances.\n",
    "        weight = 1 / (distance_metric + 1e-6) # add epsilon to avoid division by 0\n",
    "        #print(\"Weight: \", weight, '\\n')\n",
    "        weights_values.append((weight, u_j))\n",
    "    return weights_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11.468403116549295, 0.609375), (37.90090810812778, 0.9385382059800664), (5.451533630035259, 0.572682925995478), (10.249897775099143, 0.2272727272727272), (2.3295406724504337, 1.0), (2.795447504518787, 0.8333333333333338), (3.0284007577507444, 0.8461538461538459), (3.979625413416238, 0.804878049173111), (3.9064543520976662, 0.7706422018348625), (5.1767423105843635, 0.5499999999999999), (7.3910706917175375, 0.6848184818481847), (10.649240188922873, 0.78125)]\n"
     ]
    }
   ],
   "source": [
    "# Testing the find_neighbors() function:\n",
    "patient_matrix = pd.read_csv('/Users/emmadyer/Desktop/data/uc_pts/22158.csv')\n",
    "pt_id = patient_matrix.loc[0:'patient_id']\n",
    "patient_matrix = patient_matrix.drop(['index', 'patient_id', 'year'], axis=1)\n",
    "\n",
    "w_v = find_neighbors(patient_matrix, 0, 1, 'crp')\n",
    "print(w_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_wknn(k, patient_matrix, mask_matrix, lab, visit_idx, correlation_matrix, correlation_dict, means_dict):\n",
    "    ''' \n",
    "    Impute missing lab values given a patient matrix.\n",
    "\n",
    "    Inputs:\n",
    "    k (integer): k-number of neighbors to use when imputing\n",
    "    patient_matrix (DataFrame): contains labs as columns and visits as rows\n",
    "    mask_matrix (DataFrame): Boolean mask of the patient matrix where True = null\n",
    "    and False = int. \n",
    "    lab (str): lab type (column header) of the missing value\n",
    "    visit_idx (int): index in the patient matrix of the visit from which the missing value arises\n",
    "\n",
    "    Output:\n",
    "    imputed_value (int): Imputed value for the missing values of a given lab\n",
    "    for a given patient.\n",
    "    '''\n",
    "    # Loop and get data pairs to calculate d(u,v)\n",
    "    all_weights_values = []\n",
    "    value = mask_matrix.loc[visit_idx, lab]\n",
    "    # impute missing value\n",
    "    for i in range(0, patient_matrix.shape[0]):\n",
    "        if visit_idx == i: # Do not want to compare a visit to itself\n",
    "            continue\n",
    "        if mask_matrix.loc[i, lab] == True: # Make sure the comparing visit has a value\n",
    "            continue\n",
    "        else:\n",
    "            weights_values = find_neighbors(patient_matrix, visit_idx, i, lab)\n",
    "            #print(\"weights and values: \", weights_values)\n",
    "        all_weights_values = all_weights_values + weights_values\n",
    "        #print(\"All Weights: \", all_weights_values)\n",
    "    if len(all_weights_values) == 0: \n",
    "        # Set imputed value to mean if there are no neighbors\n",
    "        imputed_value = means_dict[lab]\n",
    "    else:     \n",
    "        sorted_weights_vals = sorted(all_weights_values)\n",
    "        neighbors = sorted_weights_vals[:k]  \n",
    "        w_knn, v_knn = map(list,zip(*sorted_weights_vals))\n",
    "        v_knn = np.asarray(v_knn)\n",
    "        w_knn = np.asarray(w_knn)\n",
    "        norm_weights = w_knn / sum(w_knn)\n",
    "        imputed_value = sum(v_knn * norm_weights)\n",
    "    return imputed_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit Index:  0\n",
      "Shared Labs:  ['fer', 'btwelve', 'alp', 'alt', 'crt', 'cal', 'hgb', 'mcv', 'hct', 'wbc', 'pmn', 'plt']\n",
      "Visit Index:  0\n",
      "Shared Labs:  ['fer', 'btwelve', 'alp', 'alt', 'crt', 'cal', 'hgb', 'mcv', 'hct', 'wbc', 'pmn', 'plt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8295602073238326"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test impute_wknn()\n",
    "correlation_dict = get_correlation_dict(test_ibd, lab_value_names)\n",
    "patient_matrix = pd.read_csv('/Users/emmadyer/Desktop/data/uc_pts/22158.csv')\n",
    "pt_id = patient_matrix.loc[0:'patient_id']\n",
    "patient_matrix = patient_matrix.drop(['index', 'patient_id', 'year'], axis=1)\n",
    "mask_matrix = patient_matrix.isnull()\n",
    "\n",
    "impute_wknn(4, patient_matrix, mask_matrix, 'crp', 0, correlation_matrix, correlation_dict, means_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the DataFrames\n",
    "all_dfs = [uc, cd, healthy]\n",
    "all_dfs = [uc]\n",
    "\n",
    "# Open each patient file and impute!!!!\n",
    "uc_pt_paths = os.listdir('/Users/emmadyer/Desktop/data/uc_pts')\n",
    "test_pt = ['/Users/emmadyer/Desktop/data/uc_pts/22158.csv']\n",
    "pt_file_lst = os.listdir('/Users/emmadyer/Desktop/data/test_ibd_pts')\n",
    "\n",
    "# Make a list of the lab values (column headers)\n",
    "lab_value_names = list(healthy.columns.values)\n",
    "lab_value_names = lab_value_names[1:-1]\n",
    "\n",
    "for df in all_dfs:\n",
    "    correlation_dict = get_correlation_dict(df, lab_value_names)\n",
    "    correlation_matrix = get_correlation_matrix(df, lab_value_names)\n",
    "\n",
    "    # Create mean value dictionary for the dataset to use when imputation\n",
    "    # cannot be performed (i.e. no neighbors)\n",
    "    pts_lst = []\n",
    "    mean_norm_values = []\n",
    "    for lab in lab_value_names:\n",
    "        #print(\"Lab Name: \", lab)\n",
    "        values = df[lab].fillna(0)\n",
    "        #values = values.astype(np.float16)\n",
    "        min_lab = min(values)\n",
    "        #print(\"Minimum Value: \", min_lab)\n",
    "        max_lab = max(values)\n",
    "        #print(\"Maximum Value: \", max_lab)\n",
    "        mean_value = values.mean()\n",
    "        norm_lab_val = minmax_scale(mean_value, min_lab, max_lab)\n",
    "        #print('Scaled Value: ', norm_lab_val, '\\n')\n",
    "        mean_norm_values.append(norm_lab_val)\n",
    "    means_dict = dict(map(lambda i,j : (i,j) , lab_value_names, mean_norm_values))\n",
    "\n",
    "    for pt in uc_pt_paths:\n",
    "        path = '/Users/emmadyer/Desktop/data/uc_pts/'+ pt\n",
    "        patient_matrix = pd.read_csv(path)\n",
    "        patient_id = patient_matrix.loc[0, 'patient_id']\n",
    "        patient_matrix = patient_matrix.reset_index(drop=True)\n",
    "        # Create a dataframe containing only the lab values:\n",
    "        labs_only_patient_matrix = patient_matrix.drop(['index', 'patient_id', 'year'], axis=1)\n",
    "        mask_visits = labs_only_patient_matrix.isnull()\n",
    "        for lab in lab_value_names: # look through each lab in a given visit\n",
    "            for n in range(0, labs_only_patient_matrix.shape[0]): \n",
    "                value = mask_visits.loc[n, lab] # check the value of the lab\n",
    "                if value == True: # value is missing — impute\n",
    "                    imputed_value = impute_wknn(3, \n",
    "                                                labs_only_patient_matrix, \n",
    "                                                mask_visits, \n",
    "                                                lab, \n",
    "                                                n, \n",
    "                                                correlation_matrix,\n",
    "                                                correlation_dict,\n",
    "                                                means_dict)\n",
    "                    patient_matrix.loc[n, lab] = imputed_value\n",
    "        patient_path = '/Users/emmadyer/Desktop/data/impute_test/' + str(patient_id) + '_imputed.csv'\n",
    "        patient_matrix.to_csv(patient_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Patient DataFrames into One DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/emmadyer/Desktop/data/test_ibd_pts/22158.csv\n",
      "/Users/emmadyer/Desktop/data/test_ibd_pts/20589.csv\n",
      "/Users/emmadyer/Desktop/data/test_ibd_pts/12376.csv\n",
      "/Users/emmadyer/Desktop/data/test_ibd_pts/17176.csv\n",
      "/Users/emmadyer/Desktop/data/test_ibd_pts/23944.csv\n",
      "/Users/emmadyer/Desktop/data/test_ibd_pts/16284.csv\n",
      "/Users/emmadyer/Desktop/data/test_ibd_pts/12618.csv\n",
      "/Users/emmadyer/Desktop/data/test_ibd_pts/17513.csv\n"
     ]
    }
   ],
   "source": [
    "impute_file_lst = os.listdir('/Users/emmadyer/Desktop/data/test_ibd_pts')\n",
    "test_pt = ['/Users/emmadyer/Desktop/data/impute_test/16284_imputed.csv']\n",
    "\n",
    "column_labels = []\n",
    "visit_lst = []\n",
    "df = pd.DataFrame()\n",
    "all_patients_df = pd.DataFrame()\n",
    "for pt in impute_file_lst:\n",
    "    path = '/Users/emmadyer/Desktop/data/test_ibd_pts/' + pt\n",
    "    print(path)\n",
    "    imputed_pt = pd.read_csv(path)\n",
    "    imputed_pt = imputed_pt.drop('year', axis=1)\n",
    "    for i in range(0,imputed_pt.shape[0]):\n",
    "        label = str(i + 1)\n",
    "        visit = imputed_pt.iloc[i, 2:]\n",
    "        patient_id = imputed_pt.loc[0, 'patient_id']\n",
    "        column_labels = column_labels + [x + label for x in list(visit.index)]\n",
    "        visit_lst = visit_lst + visit.to_list() \n",
    "    full_dict = dict(zip(column_labels, visit_lst))\n",
    "    df = pd.DataFrame(full_dict, index=[0])\n",
    "    df['patient_id'] = patient_id\n",
    "    all_patients_df = pd.concat([all_patients_df, df], axis=0 )\n",
    "all_patients_df.to_csv('/Users/emmadyer/Desktop/data/rejoin_master.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "819f5faae82d2b37d0a346b6fdcf3a45ded9957c5c76ee733e99f4e9e472ef0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
