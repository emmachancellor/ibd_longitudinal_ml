{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the Data and Separate Patients into Individual Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "uc = pd.read_csv('/Users/emmadyer/Desktop/ibd_long_project/data/uc_expanded.csv')\n",
    "cd = pd.read_csv('/Users/emmadyer/Desktop/ibd_long_project/data/cd_expanded.csv')\n",
    "healthy = pd.read_csv('/Users/emmadyer/Desktop/ibd_long_project/data/healthy_expanded.csv')\n",
    "test_ibd = pd.read_csv('/Users/emmadyer/Desktop/ibd_long_project/data/test_ibd_expanded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the lab values (column headers)\n",
    "lab_value_names = list(healthy.columns.values)\n",
    "lab_value_names = lab_value_names[1:-1]\n",
    "\n",
    "# Make a list of the DataFrames\n",
    "all_dfs = [uc, cd, healthy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Each Patient's Data\n",
    "# Min/Max scaling [0,1] and account for missing values\n",
    "def minmax_scale(x, min, max):\n",
    "    ''' \n",
    "    Min/Max Scaler [0,1] that also handles when the max=min.\n",
    "    Inputs:\n",
    "    x (int) - Value to be normalized\n",
    "    min (int) - minmum value\n",
    "    max (int) - maximum value\n",
    "\n",
    "    Outputs:\n",
    "    norm (int) - normalized value [0,1]\n",
    "    '''\n",
    "    if min != max:\n",
    "        scaled = max - min\n",
    "    else:\n",
    "        scaled = 1\n",
    "    norm = (x - min) / scaled\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_norms = []\n",
    "for df in all_dfs:\n",
    "    pts_lst = []\n",
    "    mean_norm_values = []\n",
    "    for lab in lab_value_names:\n",
    "        #print(\"Lab Name: \", lab)\n",
    "        values = df[lab].fillna(0)\n",
    "        #values = values.astype(np.float16)\n",
    "        min_lab = min(values)\n",
    "        #print(\"Minimum Value: \", min_lab)\n",
    "        max_lab = max(values)\n",
    "        #print(\"Maximum Value: \", max_lab)\n",
    "        mean_value = values.mean()\n",
    "        norm_lab_val = minmax_scale(mean_value, min_lab, max_lab)\n",
    "        #print('Scaled Value: ', norm_lab_val, '\\n')\n",
    "        mean_norm_values.append(norm_lab_val)\n",
    "    dataset_norms.append(mean_norm_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688\n",
      "2197\n",
      "5415\n"
     ]
    }
   ],
   "source": [
    "# Need to calculate a mean normalized value in the event that a given patient only has one recorded value or no values.\n",
    "# Mean Noramlized Values\n",
    "\n",
    "# Lists to store patient normalized dataframes\n",
    "all_patients_lsts = []\n",
    "file_names = ['uc', 'cd', 'healthy']\n",
    "for pt_population, df in enumerate(all_dfs):\n",
    "    mean_norm_values = dataset_norms[pt_population]\n",
    "    patient_id_lst = list(df.patient_id.unique())\n",
    "    print(len(patient_id_lst))\n",
    "    for patient in patient_id_lst:\n",
    "        patient_df = df[df['patient_id'] == patient].reset_index()\n",
    "        # Patient Normalized Values\n",
    "        visits = list(range(0,5))\n",
    "        na_reference_df = patient_df.copy()\n",
    "        na_reference_df = na_reference_df.isnull()\n",
    "        #norm_df = patient_df.copy().reset_index()\n",
    "        for i, lab in enumerate(lab_value_names):\n",
    "            #print(\"\\n Lab Name: \", lab)\n",
    "            total_missing = patient_df[lab].isnull().sum()\n",
    "            if total_missing == 5: \n",
    "                continue\n",
    "            else:\n",
    "                values = patient_df[lab].fillna(0)\n",
    "                min_lab = min(values)\n",
    "                max_lab = max(values)\n",
    "                #print(\"Minimum Value: \", min_lab)\n",
    "                #print(\"Maximum Value: \", max_lab)\n",
    "                for v in visits:\n",
    "                    is_missing = na_reference_df.loc[v, lab]\n",
    "                    #print(\"Missing???: \", is_missing)\n",
    "                    if is_missing == False:\n",
    "                        value = patient_df.loc[v, lab]\n",
    "                        norm_val = minmax_scale(value, min_lab, max_lab)\n",
    "                        patient_df.loc[v, lab] = norm_val\n",
    "                    #print(\"Lab Value: \", value)\n",
    "                    #print('Scaled Value: ', norm_val)\n",
    "        pts_lst.append(patient_df)\n",
    "        file_path = '/Users/emmadyer/Desktop/ibd_long_project/data/' + file_names[pt_population] + '_pts/' + str(patient) + '.csv'\n",
    "        patient_df.to_csv(file_path, index=False)\n",
    "        #print(norm_df)\n",
    "    all_patients_lsts.append(pts_lst)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Distance Correlation\n",
    "This is calculated on the whole dataset. We are solving for the distance between two vectors. In this case, we are calculating the distance correlation for the pairwise vectors for each analyte. \n",
    "1. Create individual arrays of each analyte with NA values removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "import dcor\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for Emma's Macbook \n",
    "\n",
    "# Load Datasets\n",
    "uc = pd.read_csv('/Users/emmadyer/Desktop/data/uc_expanded.csv')\n",
    "cd = pd.read_csv('/Users/emmadyer/Desktop/data/cd_expanded.csv')\n",
    "healthy = pd.read_csv('/Users/emmadyer/Desktop/data/healthy_expanded.csv')\n",
    "test_ibd = pd.read_csv('/Users/emmadyer/Desktop/data/test_ibd_expanded.csv')\n",
    "\n",
    "# Make a list of the lab values (column headers)\n",
    "lab_value_names = list(healthy.columns.values)\n",
    "lab_value_names = lab_value_names[1:-1]\n",
    "\n",
    "# Make a list of the DataFrames\n",
    "all_dfs = [uc, cd, healthy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_ibd.copy()\n",
    "individual_labs = []\n",
    "for lab in lab_value_names: \n",
    "    lab_data = df[lab].dropna()\n",
    "    lab_data = lab_data.to_numpy()\n",
    "    individual_labs.append(lab_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate the distance between each array. Need to adjust the arrays to be the same size before calculating the distance correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary of dictionaries. Structure is that the outer key is a lab name,\n",
    "# the inner key is a lab name with a value of the distance correlation between the \n",
    "# two labs specified by the keys\n",
    "\n",
    "whole_correlation_dict = dict()\n",
    "for i, lab_1 in enumerate(individual_labs):\n",
    "    all_cors = []\n",
    "    len_l1 = len(lab_1)\n",
    "    sub_correlation_dict = dict()\n",
    "    for j, lab_2 in enumerate(individual_labs):\n",
    "        len_l2 = len(lab_2)\n",
    "        min_len = min(len_l1, len_l2)\n",
    "        red_1 = lab_1[:min_len]\n",
    "        red_2 = lab_2[:min_len]\n",
    "        correlation = dcor.distance_correlation(red_1, red_2)\n",
    "        sub_correlation_dict[lab_value_names[j]] = correlation\n",
    "    whole_correlation_dict[lab_value_names[i]] = sub_correlation_dict\n",
    "\n",
    "# To test that this is working correctly, we can see that, as expected, the correlation \n",
    "# of crp to crp is 1\n",
    "whole_correlation_dict['crp']['crp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatted with a list of correlation values\n",
    "\n",
    "\n",
    "l_whole_correlation_dict = dict()\n",
    "for i, lab_1 in enumerate(individual_labs):\n",
    "    all_cors = []\n",
    "    len_l1 = len(lab_1)\n",
    "    cor_lst = []\n",
    "    for j, lab_2 in enumerate(individual_labs):\n",
    "        len_l2 = len(lab_2)\n",
    "        min_len = min(len_l1, len_l2)\n",
    "        red_1 = lab_1[:min_len]\n",
    "        red_2 = lab_2[:min_len]\n",
    "        correlation = dcor.distance_correlation(red_1, red_2)\n",
    "        cor_lst.append(correlation)\n",
    "    l_whole_correlation_dict[lab_value_names[i]] = cor_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance from the missing data point (to be imputed) to ALL\n",
    "# available values\n",
    "\n",
    "# Create a DataFrame with the correlation values (correlation matrix in a dataframe format)\n",
    "correlation_matrix = pd.DataFrame()\n",
    "correlation_matrix['lab_name'] = lab_value_names\n",
    "correlation_matrix = correlation_matrix.set_index('lab_name')\n",
    "\n",
    "for labs, cor_vals in l_whole_correlation_dict.items():\n",
    "    correlation_matrix[labs] = cor_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation Steps\n",
    "1. Land on a missing value in the patient matrix.\n",
    "2. Identify if the patient has a non-missing value for the given lab at another visit.\n",
    "3. If there are no data for this lab in any visit, impute with the population mean.\n",
    "4. If there is another data point for this lab value at another visit, calculate the weight d(u,v) between all values, including multiple values of the same lab (that have a correlation of 1)\n",
    "   \n",
    "Note: The summed MIC helps account for temporal relationships. The sum constitutes the sum of MIC for non-missing values that exist in the two vists that are being compared when calculating d(v,u). For example if a patient is missing a value for cal, but they have measurements for crp, fol, hgb, and wbc in visits 1 and 2, the the summed MIC would be calculated as the sum of the MIC values for cal|fol, cal|hgb, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open each patient file and impute!!!!\n",
    "\n",
    "uc_pt_paths = os.listdir('/Users/emmadyer/Desktop/data/uc_pts')\n",
    "test_pt = ['/Users/emmadyer/Desktop/data/uc_pts/22158.csv']\n",
    "pt_file_lst = test_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(patient_matrix, mask_matrix, value):\n",
    "    '''\n",
    "    Helper function to compute the weights of a given lab value and\n",
    "    all other available lab values. Must have correlation matrix pre-calculated. \n",
    "\n",
    "    Inputs:\n",
    "    patient_matrix (DataFrame): contains labs as columns and visits as rows\n",
    "    mask_matrix (DataFrame): Boolean mask of the patient matrix where True = null\n",
    "    and False = int. \n",
    "    value\n",
    "\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(patient_matrix, visit_v_idx, visit_u_idx, lab_to_impute, whole_correlation_dict=whole_correlation_dict):\n",
    "    ''' \n",
    "    Find the distance correlation sum between two given visits. This function\n",
    "    compares the lab values that are mutually present between two visits, accesses\n",
    "    the distance correlation between those labs, and sums the distance correlation\n",
    "    between the lab value that is missing and the lab values that contain measurments\n",
    "    in both visits. \n",
    "\n",
    "    Example: Visit 1 has lab values for cal, pro, fol, fer, hgb, hct, and wbc. Visit 2 has\n",
    "    values for alt, pro, alb, hgb, pmn, wbc, fer, btwelve, and hct. The value being imputed is \n",
    "    plt. This function identifies that both visits have lab values for pro, wbc, fer, hct, and\n",
    "    hgb. Then, it identifies the distance correlation between pro-plt, wbc-plt, fer-plt, hct-plt,\n",
    "    and hgb-plt. Finally, the identified distance correlations are summed together, which is then\n",
    "    used to calculate the distance metric. The inverse distance metric and the \n",
    "    value of the comparator visit (visit_u) are saved and used for the output.\n",
    "\n",
    "    Inputs:\n",
    "    patient_matrix (DataFrame): contains labs as columns and visits as rows\n",
    "    visit_d_idx (int): index for the visit that contains the value to be imputed.\n",
    "    visit_u_idx (int): index for the visit being compared to the visit with the value\n",
    "    that is to be imputed. \n",
    "    lab_to_impute (str): represents the lab type (column header) of the value being imputed\n",
    "\n",
    "    Outputs:\n",
    "    weights, values (tuple [list, list]): Weights of each neighbor and the value\n",
    "    of the neighbor, each stored in a list where the index of the list \n",
    "    corresponds to matching weights and values. \n",
    "    '''\n",
    "    visit_v = patient_matrix.loc[visit_v_idx,:].dropna()\n",
    "    visit_u = patient_matrix.loc[visit_u_idx, :].dropna()\n",
    "    v_labs = list(visit_v.index)\n",
    "    u_labs = list(visit_v.index)\n",
    "    shared_labs = [l for l in v_labs and u_labs if l in v_labs and l in u_labs]\n",
    "    correlation_vals = []\n",
    "    for l in shared_labs:\n",
    "        val = whole_correlation_dict[lab_to_impute][l]\n",
    "        correlation_vals.append(val)\n",
    "    sum_dis_cors = sum(correlation_vals)\n",
    "    #print(\"Distance Correlations Sum: \", sum_dis_cors, '\\n')\n",
    "    weights_values = []\n",
    "    for l in shared_labs:\n",
    "        #print('Lab: ', l)\n",
    "        v_j = visit_v.loc[l]\n",
    "        u_j = visit_u.loc[l]\n",
    "        distance_metric = math.sqrt(sum_dis_cors * (v_j - u_j)**2) / sum_dis_cors\n",
    "        #print(\"Distance Metric: \", distance_metric)\n",
    "        # Calculate the inverse of the distance metric because the smaller the distance\n",
    "        # the larger the weight (i.e. closer neighbor), we can then say that larger \n",
    "        # weights are closer, instead of working with smaller distances.\n",
    "        weight = 1 / (distance_metric + 1e-6) # add epsilon to avoid division by 0\n",
    "        #print(\"Weight: \", weight, '\\n')\n",
    "        weights_values.append((weight, u_j))\n",
    "    return weights_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11.468403116549295, 0.609375), (37.90090810812778, 0.9385382059800664), (5.451533630035259, 0.572682925995478), (10.249897775099143, 0.2272727272727272), (2.3295406724504337, 1.0), (2.795447504518787, 0.8333333333333338), (3.0284007577507444, 0.8461538461538459), (3.979625413416238, 0.804878049173111), (3.9064543520976662, 0.7706422018348625), (5.1767423105843635, 0.5499999999999999), (7.3910706917175375, 0.6848184818481847), (10.649240188922873, 0.78125)]\n"
     ]
    }
   ],
   "source": [
    "# Testing the find_neighbors() function:\n",
    "patient_matrix = pd.read_csv('/Users/emmadyer/Desktop/data/uc_pts/22158.csv')\n",
    "pt_id = patient_matrix.loc[0:'patient_id']\n",
    "patient_matrix = patient_matrix.drop(['index', 'patient_id', 'year'], axis=1)\n",
    "\n",
    "w_v = find_neighbors(patient_matrix, 0, 1, 'crp')\n",
    "print(w_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_wknn(k, patient_matrix, mask_matrix, lab, visit_idx, correlation_matrix=correlation_matrix):\n",
    "    ''' \n",
    "    Impute missing lab values given a patient matrix.\n",
    "\n",
    "    Inputs:\n",
    "    k (integer): k-number of neighbors to use when imputing\n",
    "    patient_matrix (DataFrame): contains labs as columns and visits as rows\n",
    "    mask_matrix (DataFrame): Boolean mask of the patient matrix where True = null\n",
    "    and False = int. \n",
    "    lab (str): lab type (column header) of the missing value\n",
    "    visit_idx (int): index in the patient matrix of the visit from which the missing value arises\n",
    "\n",
    "    Output:\n",
    "    imputed_value (int): Imputed value for the missing values of a given lab\n",
    "    for a given patient.\n",
    "    '''\n",
    "    # Loop and get data pairs to calculate d(u,v)\n",
    "    all_weights_values = []\n",
    "    value = mask_matrix.loc[visit_idx, lab]\n",
    "    # impute missing value\n",
    "    for i in range(0, len(patient_matrix.rows.values)):\n",
    "        if visit_idx == i: # Do not want to compare a visit to itself\n",
    "            continue\n",
    "        if mask_matrix.loc[i, lab] == True: # Make sure the comparing visit has a value\n",
    "            continue\n",
    "        else:\n",
    "            weights_values = find_neighbors(patient_matrix, visit_idx, i, lab)\n",
    "        all_weights_values = all_weights_values + weights_values\n",
    "    sorted_weights_vals = sorted(all_weights_values)\n",
    "    neighbors = sorted_weights_vals[:k]  \n",
    "    w_knn, v_knn = map(list,zip(*sorted_weights_vals))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 1, 3]\n",
      "[4, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "l = [(5,4), (1,2), (3,4)]\n",
    "w = [(1,2), (2,1)]\n",
    "s = l[:3]\n",
    "#print(s)\n",
    "w, v = map(list,zip(*l))\n",
    "print(w)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_num = list(range(0,5))\n",
    "\n",
    "for pt in pt_file_lst:\n",
    "    visits = pd.read_csv(pt)\n",
    "    visits = visits.reset_index()\n",
    "    pt_id = visits.loc[0:'patient_id']\n",
    "    visits = visits.drop(['index', 'patient_id', 'year'], axis=1)\n",
    "    mask_visits = visits.isnull()\n",
    "    for lab in lab_value_names: # look through each lab in a given visit\n",
    "        for n in v_num: # check the value of the lab\n",
    "            value = mask_visits.loc[n, lab]\n",
    "            if value == True: # value is missing â€” impute\n",
    "                impute_wknn()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "819f5faae82d2b37d0a346b6fdcf3a45ded9957c5c76ee733e99f4e9e472ef0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
